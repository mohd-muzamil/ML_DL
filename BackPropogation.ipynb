{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BackPropogation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9j3ngwik+Z+VtT1SW1ly5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohd-muzamil/Deep-Learning/blob/main/BackPropogation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAqcXePV7JVG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f03_FBSQ_oRM"
      },
      "source": [
        "from sklearn import datasets\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaOWTF7L28AV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\r\n",
        "\r\n",
        "dataset = datasets.load_breast_cancer()\r\n",
        "x = dataset['data']\r\n",
        "y = dataset['target']\r\n",
        "\r\n",
        "# One hot encoding\r\n",
        "enc = OneHotEncoder()\r\n",
        "y = enc.fit_transform(y[:, np.newaxis]).toarray()\r\n",
        "\r\n",
        "# Scale data to have mean 0 and variance 1 \r\n",
        "# which is importance for convergence of the neural network\r\n",
        "scaler = StandardScaler()\r\n",
        "x_scaled = scaler.fit_transform(x)\r\n",
        "\r\n",
        "# Split the data set into training and testing\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.5, random_state=2)\r\n",
        "\r\n",
        "n_features = x.shape[1]\r\n",
        "n_classes = y.shape[1]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqA59eaWBE2r"
      },
      "source": [
        "# # data, target = datasets.load_breast_cancer(return_X_y=True)   #Breast Cancer dataset\r\n",
        "# data, target = datasets.load_iris(return_X_y=True)   #MNIST Dataset\r\n",
        "# np.random.shuffle(data)\r\n",
        "# np.random.shuffle(target)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI2nWIRO7mvn"
      },
      "source": [
        "# def one_hot_y(Y):\r\n",
        "#   one_hot_size = max(Y) + 1\r\n",
        "#   Y = Y.astype(np.int64)\r\n",
        "#   one_hot = np.zeros((Y.size, one_hot_size))\r\n",
        "#   one_hot[np.arange(Y.size), Y] = 1\r\n",
        "#   # one_hot = one_hot.T\r\n",
        "#   return one_hot"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaaqHcSN8SKH"
      },
      "source": [
        "# m, n = data.shape[0], data.shape[1]\r\n",
        "# split = int(0.9 * m)\r\n",
        "\r\n",
        "# x_train = data[0:split]\r\n",
        "# y_train = target[0:split]\r\n",
        "\r\n",
        "# x_test = data[split:m]\r\n",
        "# y_test = target[split:m]\r\n",
        "\r\n",
        "# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0grtbM7tKqx9"
      },
      "source": [
        "def activation_function(activation, x):\r\n",
        "  activation = str.lower(activation)\r\n",
        "  if activation == 'sigmoid':\r\n",
        "    out = 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "  elif activation == 'relu':\r\n",
        "    out = np.maximum(0, x)\r\n",
        "\r\n",
        "  elif activation == 'softmax':\r\n",
        "    out = np.exp(x) / (sum(np.exp(x)+10e-10))\r\n",
        "\r\n",
        "  elif activation == 'linear':\r\n",
        "    out = x\r\n",
        "  return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ibyFeKxY0QM"
      },
      "source": [
        "def deriv_activation(activation, x):\r\n",
        "  activation = str.lower(activation)\r\n",
        "  if activation == 'sigmoid':\r\n",
        "    out = 1 / (1 + np.exp(-x))\r\n",
        "    grad = out * (1 - out)\r\n",
        "\r\n",
        "  elif activation == 'relu':\r\n",
        "    # grad = np.asarray([1 if val>0 else 0 for val in x])\r\n",
        "    grad = x>0\r\n",
        "\r\n",
        "  elif activation == 'linear':\r\n",
        "    grad = 1\r\n",
        "  \r\n",
        "  return grad\r\n",
        "  # return np.expand_dims(grad, axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnOMjP36BodS"
      },
      "source": [
        "class model():\r\n",
        "  def __init__(self, layers_size, activation):\r\n",
        "    self.layers_size = layers_size\r\n",
        "    self.activation = activation\r\n",
        "    self.weights = []\r\n",
        "    self.bais = []\r\n",
        "\r\n",
        "    for layer in zip(layers_size, layers_size[1:]):\r\n",
        "      self.weights.append(np.random.randn(layer[1], layer[0]) / np.sqrt(layer[0]))\r\n",
        "      self.bais.append(np.random.randn(layer[1], 1))\r\n",
        "\r\n",
        "  def forward_pass(self, x):\r\n",
        "    self.inputs = []\r\n",
        "    self.outputs = []\r\n",
        "    # print(f'Forward Pass')\r\n",
        "\r\n",
        "    x = np.expand_dims(x, axis=1)  #only for batch_size = 1\r\n",
        "\r\n",
        "    for layer in range(len(self.layers_size)-1):\r\n",
        "      # print(f'x{x.shape}')\r\n",
        "      self.outputs.append(x)\r\n",
        "\r\n",
        "      W = self.weights[layer]\r\n",
        "      B = self.bais[layer]\r\n",
        "      # print(f'layer{layer} W{W.shape} @ x{x.shape} + b{B.shape}')\r\n",
        "      Z = W @ x + B\r\n",
        "      A = activation_function(self.activation[layer], Z)\r\n",
        "      # print(f'Z{Z}\\nA{A}')\r\n",
        "\r\n",
        "      self.inputs.append(Z)\r\n",
        "      x = A\r\n",
        "\r\n",
        "    # for layer,(i,o) in enumerate(zip(self.inputs, self.outputs)):\r\n",
        "    #   print(f'Z{layer}{i.shape} A{layer}{o.shape}')\r\n",
        "    return A\r\n",
        "\r\n",
        "  def backward_pass(self, dZ, batch_size=1, learning_rate=0.01):\r\n",
        "    # print(\"Backward Pass\")\r\n",
        "    for layer in reversed(range(len(self.layers_size)-1)):\r\n",
        "      # print(f'layer{layer}')\r\n",
        "      \r\n",
        "      # print(f'dZ{dZ.shape} @ A.T{self.outputs[layer].T.shape})')\r\n",
        "      dW = 1/batch_size * dZ @ self.outputs[layer].T\r\n",
        "      # dB = 1/batch_size * np.sum(dZ)\r\n",
        "      dB = 1/batch_size * dZ @ np.ones((batch_size,1))\r\n",
        "      # print(f'Updating delta dZ............')\r\n",
        "      # print(f'W.T{self.weights[layer].T.shape} @ dZ{dZ.shape} * g`(Z{layer-1}{self.inputs[layer-1].shape})')\r\n",
        "      \r\n",
        "      if layer!=0:\r\n",
        "        # print(f'{deriv_activation(activation=self.activation[layer-1],x=self.inputs[layer-1]).shape}')\r\n",
        "        dZ = self.weights[layer].T @ dZ * deriv_activation(activation=self.activation[layer-1],x=self.inputs[layer-1])\r\n",
        "      \r\n",
        "      # print(f'new delta dZ{dZ.shape}')\r\n",
        "      # print(f'dW{dW.shape} dB{dB.shape}')\r\n",
        "      self.weights[layer] -= learning_rate * dW \r\n",
        "      self.bais[layer] -= learning_rate * dB "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkAJYG42fjui"
      },
      "source": [
        "def get_accuracy():\r\n",
        "  predictions = []\r\n",
        "  Y = []\r\n",
        "  for x, y in zip(x_test, y_test):\r\n",
        "    ypred = MLP.forward_pass(x).argmax()\r\n",
        "    predictions.append(ypred)\r\n",
        "    Y.append(y.argmax())\r\n",
        "\r\n",
        "  # accuracy_score = np.sum(predictions == Y) / Y.size\r\n",
        "  accuracy = accuracy_score(Y, predictions)\r\n",
        "  return round(accuracy, 4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXFyBTyumD8y"
      },
      "source": [
        "def cross_entropy(predictions, targets, epsilon=1e-12):\r\n",
        "    \"\"\"\r\n",
        "    Computes cross entropy between targets (encoded as one-hot vectors)\r\n",
        "    and predictions. \r\n",
        "    Input: predictions (N, k) ndarray\r\n",
        "           targets (N, k) ndarray        \r\n",
        "    Returns: scalar\r\n",
        "    \"\"\"\r\n",
        "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\r\n",
        "    N = predictions.shape[0]\r\n",
        "    ce = -np.sum(targets*np.log(predictions+1e-9))/N\r\n",
        "    return ce"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K9AlI_TBmuT",
        "outputId": "8c9b48cd-938d-4bdf-f804-9aa5c50da1f7"
      },
      "source": [
        "input_size = x_train.shape[1]\r\n",
        "output_size = y_train.shape[1]\r\n",
        "\r\n",
        "layers_size = [input_size, 8, 8, output_size]\r\n",
        "activation = []\r\n",
        "for layer in range(len(layers_size)-2):\r\n",
        "  activation.append('relu')\r\n",
        "activation.append('softmax')\r\n",
        "\r\n",
        "print(layers_size, activation)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[30, 8, 8, 2] ['relu', 'relu', 'softmax']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "CzGzFIv2Fr6U",
        "outputId": "077b7c86-6b29-4807-8fdd-7e06bf5da8ff"
      },
      "source": [
        "MLP = model(layers_size, activation)\r\n",
        "#Training the model using Cross Entropy loss\r\n",
        "\r\n",
        "epocs = 10\r\n",
        "learning_rate = 0.1\r\n",
        "overall_loss = []\r\n",
        "overall_accuracy = []\r\n",
        "for epoc in range(epocs):\r\n",
        "  loss = []\r\n",
        "  for count, (datum, y) in enumerate(zip(x_train, y_train)):\r\n",
        "    # ypred = np.squeeze(MLP.forward_pass(datum.T))\r\n",
        "    ypred = MLP.forward_pass(datum.T)\r\n",
        "\r\n",
        "    # print('*********************')\r\n",
        "    # loss.append(0.5 * np.sum((ypred - one_hot_y(y))**2))\r\n",
        "    l = cross_entropy(ypred, y)\r\n",
        "    loss.append(l)\r\n",
        "    y = np.expand_dims(y, 1)\r\n",
        "    # print(f'ypred{ypred.shape} y{y.shape}')\r\n",
        "    # print(f'ypred_val{ypred} y_val{(y)}')\r\n",
        "    dZ = (ypred - y)\r\n",
        "    # print(f'dZ{dZ} {dZ.shape}')\r\n",
        "    # if count%100==0:\r\n",
        "    #   print('*********************')\r\n",
        "    #   print(f'Actual Value:{y} Predicted Value: {ypred}')\r\n",
        "    #   print(f'loss {round(loss[-1], 4)}, dZ{dZ}')\r\n",
        "    MLP.backward_pass(dZ, learning_rate=learning_rate)\r\n",
        "\r\n",
        "  \r\n",
        "  agg_loss = np.mean(loss)\r\n",
        "  overall_loss.append(agg_loss)\r\n",
        "  # ypred  = MLP.predict(x_test.T)\r\n",
        "  accuracy = get_accuracy()\r\n",
        "  overall_accuracy.append(accuracy)\r\n",
        "  if epoc%2==0:\r\n",
        "    print(f'epoc: {epoc} Training loss: {round(agg_loss, 4)} Test Accuracy: {accuracy}') \r\n",
        "    learning_rate *= 0.75\r\n",
        "\r\n",
        "plt.subplot(2,1,1)\r\n",
        "plt.plot(overall_loss)\r\n",
        "plt.subplot(2,1,2)\r\n",
        "plt.plot(overall_accuracy)\r\n",
        "plt.show"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoc: 0 Training loss: 2.5037 Test Accuracy: 0.9333\n",
            "epoc: 2 Training loss: 4.7255 Test Accuracy: 0.9579\n",
            "epoc: 4 Training loss: 6.1514 Test Accuracy: 0.9649\n",
            "epoc: 6 Training loss: 6.553 Test Accuracy: 0.9614\n",
            "epoc: 8 Training loss: 6.8747 Test Accuracy: 0.9649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JypbvTqqrb32",
        "outputId": "7b398d2a-a2e7-4bd3-8915-5a1dac4cf5da"
      },
      "source": [
        "#Keras implentation for Cross checking the results\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "def add_layer(hidden_nodes, n_in, activation):\r\n",
        "  model.add(Dense(hidden_nodes, input_dim=n_in, activation=activation))\r\n",
        "\r\n",
        "for layer in range(len(layers_size)-2):\r\n",
        "  add_layer(layers_size[layer+1], layers_size[layer], activation=activation[layer])\r\n",
        "\r\n",
        "model.add(Dense(layers_size[-1], activation=activation[-1]))\r\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "\r\n",
        "model.summary()\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 8)                 248       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 72        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 18        \n",
            "=================================================================\n",
            "Total params: 338\n",
            "Trainable params: 338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STtTPJtkwveP"
      },
      "source": [
        "# #Dependencies\r\n",
        "# import keras\r\n",
        "# from keras.models import Sequential\r\n",
        "# from keras.layers import Dense\r\n",
        "# # Neural network\r\n",
        "# model = Sequential()\r\n",
        "# model.add(Dense(8, input_dim=4, activation='relu'))\r\n",
        "# model.add(Dense(8, activation='relu'))\r\n",
        "# model.add(Dense(3, activation='softmax'))\r\n",
        "\r\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FsvP2MCw5HU",
        "outputId": "6567710c-4c9c-4758-b997-fe60030ae6a7"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=20, batch_size=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "284/284 [==============================] - 1s 1ms/step - loss: 0.3911 - accuracy: 0.8821\n",
            "Epoch 2/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9608\n",
            "Epoch 3/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9715\n",
            "Epoch 4/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9821\n",
            "Epoch 5/20\n",
            "284/284 [==============================] - 0s 993us/step - loss: 0.0424 - accuracy: 0.9886\n",
            "Epoch 6/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9965\n",
            "Epoch 7/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9914\n",
            "Epoch 8/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9933\n",
            "Epoch 9/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9924\n",
            "Epoch 10/20\n",
            "284/284 [==============================] - 0s 987us/step - loss: 0.0140 - accuracy: 0.9965\n",
            "Epoch 11/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9956\n",
            "Epoch 12/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9997\n",
            "Epoch 13/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9980\n",
            "Epoch 14/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9954\n",
            "Epoch 15/20\n",
            "284/284 [==============================] - 0s 978us/step - loss: 0.0136 - accuracy: 0.9956\n",
            "Epoch 16/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9972\n",
            "Epoch 17/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0066 - accuracy: 0.9993\n",
            "Epoch 19/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9965\n",
            "Epoch 20/20\n",
            "284/284 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eDrAMuE1Q1O"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}